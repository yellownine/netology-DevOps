# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её
нужно прервать.

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

**Ответ**

Для остановки запроса пользователя
- посмотрю текущие выполняемые операции с помощью `db.currentOp({'secs_running':{$gte:1800}})`.
- найду opid операции, выполняемой более 3 минут.
- сделаю `db.killOp(opid)`.

Вариант решения проблемы:
- проверить, есть ли индекс для коллекции, к которой обращался пользователь, и в каком он состоянии. Если нет индекса, то создать.
Если индекс есть, то определить его состояние (пока не знаю, как, т.к. нет опыта) и при необходимости запланировать переиндексирование.
- проверить состояние нод в кластере БД: возможно какие-то ноды отвалились, и скоро придет еще пользователи с жалобами.
- проверить состояние реплик в кластере БД с той же позиции.
- запросить у пользователя вывод какого-нибудь traceroute - возможно пользователь аутсорсит слишком издалека да еще и с мобильного телефона.   
- запущу профилировщик, чтобы собирать информацию о том, где есть узкие места.
- соберу побольше информации о том, как. когда и почему глючит БД. И уже после этого буду гуглить решение.

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL.
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса.

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

**Ответ**
- Реплики сервиса делают записи по одному и тому же ключу, еще не истёкшему

## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

**Ответ**

- 'SELECT..... ' по большому количеству записей подразумевает долгую обработку - наступает timeout.
Рекомендуется увеличить 'net_read_timeout'
- так же по возможности надо увеличить количество реплик БД, разместить их на разных (географически) серверах, учитывая то, откуда пользователи делают запросы.

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

**Ответ**

По мере увеличения объема хранимых данных БД начала угрожать стабильности хоста, т.к. стала отъедать слишком много памяти. За это хост натравил на postmaster (важный для БД процесс) oom-killer, который ее и прибил.  
Видимо, стоит попробовать для начала:
- почекать хост через `free -m` и может перенастроить как-то хост
- оптимизировать индексы в БД. Посмотреть статистику и продумать какое-нибудь шардирование с последующей переиндексацией.
- переехать на сервер с увеличенными ресурсами
- возможно пора прикрутить pgbouncer

---

### Доработка ответа по Задаче 4 после комментариев проверяющего.
> Добрый день!
>
Ответ на 4-й вопрос не верный.
>
Во-первых, OOM killer это следствие, а не причина.

У меня нет иной версии причины срабатывания oom-killer'а кроме как "достигнут предел использования оперативной памяти".
>
Во-вторых, а что если у вас нет ресурсов для увеличения оперативной памяти и масштабирования сервиса, а проблему решать нужно здесь и сейчас.

В связи с этим предлагаю следующие решения:
1. Уменьшить максимальное количество соединений с БД. В интернетах пишут, что на соединение приходится 1.5-15 Мб RAM. Дополнительно [Здесь](https://www.postgresql.org/message-id/45E811CB.8040300@oss.ntt.co.jp) предлагают увеличить swap.
2. Включить мониторинг хоста/виртуальной машины, на которой работает БД, и посмотреть, какие процессы помимо БД подъедают оперативную память. Может есть что-то лишнее.
3. Если реплик БД было несколько, то проверить их состояние - все ли реплики работают: вдруг осталась одна, и она взяла на себя всю нагрузку.
4. Объяснить oom-killer'у, что убивать БД не стоит. Сделать это можно, отредактировав файл /proc/$PID/oom_adj. В этот файл надо записать -15, а то и вообще -17.
5. Если ничего не помогает - вернуться на MySQL.
