# 1.1. Введение в DevOps — Аронов Леонид
***
## Задание №2 - Описание жизненного цикла задачи (разработки нового функционала)

* ### Формулировка описания нового функционала
  <p>Продукт-менеджер совместно с клиентом или отделом маркетологов формулирует описание нового функционала.</p>
  <p>Реузльтатом их работы является набросок в Figma и словесное описание функционала (use-cases).</p>
* ### Оценка времени реализации нового функционала 
  <p>Проджект-менеджер с помощью тим-лида или непосредственно общаясь с командой разработчиков оценивает время, необходимое на реализацию нового функционала.</p>
  <p>Полученная оценка времени согласуется с продукт-менеджером и клиентом/заказчиком/маркетологами.</p>
* ### Проектирование/доработка текущего проека в части нового функционала
  <p>Проджект-менеджер возможно совместно с тим- и тех-лидом проектирует новый функционал в части входных выходных интерфесов, стараясь не нарушить логику того, что уже есть</p>
  <p>DevOps-инженер согласует с проджект-менеджером инфраструктуру для работы над проектом:
  
    - необходимый набор серверов внутри организации или облачных сервисов;
    - настраивает pipeline, runner'ы и все такое, что позволяет в автоматическом режиме создавать изолированное окружение, его инициализацию, запуск тестов, логирование результатов тестов и мониторинг
    - согласует с командой разработчиков аспекты их работы, затрагивающие CI/CD, чтобы все всё одинаково понимали, помогает им с настройкой среды разработки, снабжает команду разработчиков необходимыми токенами/паролями/ключами/креденшелзами, чтобы они могли выкатывать свой продукт в репозиторгий и pipeline
    - настраивает инфраструктуру в части сохранности рабочего кода (веток/коммитов), возможности отката назад
  </p>
* ### Работа над проектом
  <p>После согласования проджект-менеджер составляет roadmap, планирует первые и следующий спринты, если принята такая модель работы над проектом.</p>
  <p>Команда разработчиком работает по спринтам, а DevOps следят за тем, что настроенная ими инфраструктура позволяет делать то, что должна делать</p>
  <p>DevOps следит за результатами работы команды разработчиков, состоянием всяких секретов, необходимых для dev и prod</p>
  <p>DevOps заряжает свой ноутбук перед сном, чтобы быть готовым в любой момент по логам удаленных серверов перезапустить runner'ы и прочие сервисы автоматизации, прочитать документацию очередного обновления Kubernetes, чтобы вернуть кластер в рабочий режим, или заказать еще мощностей для масштабирования после того, как разработчики выкатили фитчу на тему AR</p>
  <p>DevOps перечитывает книжки дядюшки Боба, чтобы не налепить монстра на кастылях, а сделать все как надо. Ведь инфраструктура - это тоже проект со своей структурой и арзитектурой, все должно быть на своих местах!</p>

* ### Выкат нового функционала потребителю
  <p>Команда разработчиков делает финальный ручной мердж в master, все проходит ожидаеме гладко, срабатывает сценарий выкатки новой версии продукта.</p>
  <p>Пока все работает в автоматическом режиме, DevOps отвечает на вопросы в stackoverflow, сабмитит свои новые идеи разработчикам используемых им инструментов, пишет свои супер-скрипты на питоне или bash, изучает новые инструменты (Pulumi?).</p>


<details>
<summary><strong>P.S.</strong></summary>
Вообще не имея некоторого опыта в области CI/CD, по материалам первого вебинара, на мой взгляд, очень сложно внятно сформулировать аспекты роли devops'а, ведь их надо буквально додумывать самостоятельно, а это уже не обучение, а скорее личный опыт.
Простите за возможно необоснованную критику, может я пока еще что-то не так понимаю, но к концу курса, надеюсь, все пойму и все смогу:)
</details>


# Материалы домашнего задания на тему «2.1. Системы контроля версий.»
1. Добавили что-то в файл README.md и посмотрели на вывода команды
```bash
git status
```
2. Проверили вывод команды `git diff` и `git diff --staged`. Первая выводит разницу между текущим (модифицированным) состоянием файла.
Вторая команда показала разницу между подготовленными к комиту изменениями (staged) и уже закомиченным (в HEAD) состоянием. 
Т.к. новые изменения не были переведены в состояние staged, то вывод был пустой.
3. Добавили изменения в следующий коммит. Теперь вывод команд поменялся: `git diff` не показывает ничего, `git diff --staged` показывает то, что было измененено, но еще не закомичено.

   **Пришлось воспользоваться командой `git rebase`, чтобы вставить коммит в историю версий, т.к. забыл указать сообщение к коммиту в соответствии с заданием. Возникшие конфликты мерджа поправил вручную**
4. Подготовили папку для конфигурации terraform, создали там локальный .gitignore, в котором задали следующие настройки для git'а:
   1. не индексировать подпапки и их содержимое с именем `.terraform` на любом уровне вложенности
   2. не индексировать файлы с расширением `.tfstate` на любом уровне вложенности
   3. не индексировать файлы, в имени которых есть строка `.tfstate.` на любом уровне вложенности
   4. не индексировать файлы с именем crash.log на любом уровне вложенности
   5. не индексировать файлы с расширением `.tfvars` на любом уровне вложенности
   6. не индексировать файлы с именами `override.tf`, `override.tf.json`, а также заканчивающиеся на `_override.tf`, и `_override.tf.json`
   7. не индексировать файлы с именами `.terraformrc` и `terraform.rc`

**Эти настройки работают только относительно папки /terraform и ее подпапок**

# Merge and  Rebase
1. Эксперимент с rebase
2. Приступили к изучению слияний, мержев и ребейза


# Домашнее задание к занятию "3.1. Работа в терминале, лекция 1"

п.8 
- Q1: какой переменной можно задать длину журнала history, и на какой строчке manual это описывается?
  - A1.1: Имя переменной HISTSIZE
  - A1.2: Описание переменной начинается со строки 1178 из 6175

- Q2: что делает директива ignoreboth в bash?
  - A2: HISTCONTROL\
              A colon-separated list of values controlling how commands are saved on the history list.  If the list of values includes ignorespace, lines which begin with a space character are not saved in the history list.  A value
              of ignoredups causes lines matching the previous history entry to not be saved.  A value of ignoreboth is shorthand for ignorespace and ignoredups.  A value of erasedups causes all previous lines matching  the  current
              line to be removed from the history list before that line is saved.  Any value not in the above list is ignored.  If HISTCONTROL is unset, or does not include a valid value, all lines read by the shell parser are saved
              on the history list, subject to the value of HISTIGNORE.  The second and subsequent lines of a multi-line compound command are not tested, and are added to the history regardless of the value of HISTCONTROL.
  - Судя по всему ignoreboth - это ключ, который указывается среди прочих в переменной окружения HISTCONTROL и указывает оболочке не записывать в историю команды, начинающиеся с пробела, а также не дублировать в истории одинаковые команды идущие подряд.

п.9
- Q: В каких сценариях использования применимы скобки {} и на какой строчке man bash это описано?
  - A: { list; }\
              list  is  simply  executed in the current shell environment.  list must be terminated with a newline or semicolon.  This is known as a group command.  The return status is the exit status of list.  Note that unlike the
              metacharacters ( and ), { and } are reserved words and must occur where a reserved word is permitted to be recognized.  Since they do not cause a word break, they must be separated from list by  whitespace  or  another
              shell metacharacter.
  - Это синтаксис для выполнения списка (list) команд в ТЕКУЩЕМ окружении.
  - Описание начинается на строке 196 из 3219

п.10
- Q: С учётом ответа на предыдущий вопрос, как создать однократным вызовом touch 100000 файлов? Получится ли аналогичным образом создать 300000? Если нет, то почему?
  - A1: touch {1..100000}
  - A2: Нельзя. В настройках limits.h через соотношение константы ARG_MAX и размера стека определяется максимальное число допустимых аргументов для функции (так говорит google). Можно поробовать через цикл.

п.11
- Q: В man bash поищите по /\[\[. Что делает конструкция [[ -d /tmp ]]
  - A: `[[ expr ]]` - это проверка `expr` на соответствие True/False. Возвращает 0 или 1. Выражение `-d/tmp` для test проверяет, существует ли файл /tmp и является ли он директорией (опять же без гугла чисто по man, я бы долго доходил до man test).

п.12
- Q: Основываясь на знаниях о просмотре текущих (например, PATH) и установке новых переменных; командах, которые мы рассматривали, добейтесь в выводе type -a bash в виртуальной машине наличия первым пунктом в списке:
```bash
bash is /tmp/new_path_directory/bash
bash is /usr/local/bin/bash
bash is /bin/bash
```
  - A: 
```bash
mkdir -p /tmp/new_path_directory/
cp /usr/local/bin/bash /tmp/new_path_directory/bash
PATH=/tmp/new_path_directory:$PATH
```

п.13
- Q: Чем отличается планирование команд с помощью batch и at?
  - A: `at`      executes commands at a specified time. (запуск команд из файла в определенное время)\
       `batch`   executes commands when system load levels permit; in other words, when the load average drops below 1.5, or the value specified in the invocation of atd. (запуск команд из файла, когда уровень загрузки системы позволяет это сделать). Уровень загрузки системы - это системный показатель, метрика (опять же гугл).


# Домашнее задание к занятию "3.2. Работа в терминале, лекция 2"

Q1: Какого типа команда cd? Попробуйте объяснить, почему она именно такого типа; опишите ход своих мыслей, если считаете что она могла бы быть другого типа.\
A1: 
```bash
type cd
cd is a shell builtin
```
Команда cd - это команда, встроенная в оболочку (shell). Ее назначение - изменять текущую директорию в соответствии с аргументом команда. Оболочка является программой для общения с ядром *'nix. На просторах интернета пишут, что команды, которые так или иначе изменяют состояние оболочки, очевидно, должны быть встроенными (подозреваю, что тут речь о правильном проектировании, области видимости и безопасности). Мои личные соображения: некоторые команды должны быть частью оболочки по принципу "минимального набора инструментов": перейти в директорию, где лежат скрипты, чтобы эти скрипты запустить.

Q2: Какая альтернатива без pipe команде grep <some_string> <some_file> | wc -l? man grep поможет в ответе на этот вопрос. Ознакомьтесь с документом о других подобных некорректных вариантах использования pipe.\
A2: 
```bash
grep -c <some_string> <some_file>
```
Отдельное спасибо за материалы на тему Useless Use of &lt;some bash&gt;.

Q3: Какой процесс с PID 1 является родителем для всех процессов в вашей виртуальной машине Ubuntu 20.04?\
A3: Это процесс systemd или init (расположение в системе /sbin/init). Вот что говорит про этот процесс man /sbin/init:
- systemd is a system and service manager for Linux operating systems. When run as first process on boot (as PID 1), it acts as init system that brings up and maintains userspace services. Separate instances are started for
       logged-in users to start their services.
- Т.е. это менеджре систем и сервисов. Это тот процесс, который загружается первым при старте Linux. Он инициализирует рабочее окружение (сервисы) каждого пользователя. При этом для каждого залогиневшегося в систему пользователя запускается свой экземпляр сервиса systemd/init.

Q4: Как будет выглядеть команда, которая перенаправит вывод stderr ls на другую сессию терминала?
A4: 
```bash
<'ls' comand use> 2>/dev/ttys003
```
пример для теста
```bash
ls -y 2>/dev/ttys003
```
В этом примере я обращаюсь к команде `ls` с недопустимым ключом `-y` и перенаправляют вывод stderr (его дескриптор - 2) на устройство терминала, которое в моей текущей сессии зарезервировано за терминалом виртуальной машины с сессией Ubuntu.

Q5: Получится ли одновременно передать команде файл на stdin и вывести ее stdout в другой файл? Приведите работающий пример.\
A5: Не уверен, что правильно понял комментарий преподавателя. Update:
```bash
cat file > <comand> > new_file
```
Пример:
```bash
cat file > echo > new_file
```

Q6: Получится ли находясь в графическом режиме, вывести данные из PTY в какой-либо из эмуляторов TTY? Сможете ли вы наблюдать выводимые данные?\
A6: Либо я чего-то не понял, либо ответ на этот вопрос дается решением на вопрос №4. Находясь в псевдотерминале (PTY) можно сформировать команду, в которой поток вывода перенаправлен на другое устройство. В качестве этого другого устройства достаточно выбрать соответствующий файл в /dev/tty***. Вопрос только в том, что доступно (область видимости) из текущей сессии. Увидеть результат вывода можно, естественно в том терминале, куда передан вывод, в текущем терминале не будет ничего.

Q7: Выполните команду bash 5>&1. К чему она приведет? Что будет, если вы выполните echo netology > /proc/$$/fd/5? Почему так происходит?\
A7: `bash 5>&1` приводит к созданию в текущей сессисии нового файлового дескриптора с номером 5 (его расположение в системе /proc/$$/fd/5, здесь $$ - это ссылка на процесс текущей сессии). Дополнительно вывод через этот файловый дескриптор перенаправляется на stdout текущей сесси. Поэтому команда `echo netology > /proc/$$/fd/5` просто передает строку `netology` в файловый дескриптор 5, а оттуда строка уже перенаправляется в stdout. Результат тот же, что и от команды `echo netology`.

Q8: Получится ли в качестве входного потока для pipe использовать <b><u>только</u></b> stderr команды, не потеряв при этом отображение stdout на pty? Напоминаем: по умолчанию через pipe передается только stdout команды слева от | на stdin команды справа. Это можно сделать, поменяв стандартные потоки местами через промежуточный новый дескриптор, который вы научились создавать в предыдущем вопросе.\
A8: Update после комментариев преподавателя:
```bash
<comand1> 3>&1 1>&2 2>&3 3>&- | <comand2>
```
I want to be a nice citizen (почитвать [тут](https://catonmat.net/bash-one-liners-explained-part-three))

Q9: Что выведет команда cat /proc/$$/environ? Как еще можно получить аналогичный по содержанию вывод?
A9: Команда выводит перечень переменных окружения и их значения для текущего ($$) процесса. При этом этот перечень соответствует состоянию, когда процесса только запускался. Похожу информацию можно получить, набрав в cmd `env` (/usr/bin/env) с той разницей, что там будут не только те переменные, с которыми была запущена сессия, но новые переменные, определенные во время сессии.

Q10: Используя man, опишите что доступно по адресам /proc/<PID>/cmdline, /proc/<PID>/exe.
A10: 
- По адресу `/proc/<PID>/cmdline` доступно представление команды, с помощью которой порожден процесс с pid=\<PID\>. К зомби-процессам это не относится, для них тут будет пусто (так пишут)
- По адресу `/proc/<PID>/exe` доступна символьная ссылка, содержащаю путь к команде, породившей процесс. То есть по этому адресу можно создать еще одгну копию процесса. 

Q11: Узнайте, какую наиболее старшую версию набора инструкций SSE поддерживает ваш процессор с помощью /proc/cpuinfo\
A11: 
- sse 
- sse2
- sse4_1
- sse4_2
man говорит, что `lscpu` тоже можно загрепать на этот вопрос.

Q12: При открытии нового окна терминала и vagrant ssh создается новая сессия и выделяется pty. Это можно подтвердить командой tty, которая упоминалась в лекции 3.2. Однако:
```bash
vagrant@netology1:~$ ssh localhost 'tty'
not a tty
```

Почитайте, почему так происходит, и как изменить поведение.

A12: Из того, что видел в интернетах и из того, что встретилось в задаче 4 текущего ДЗ могу сделать такой вывод. При создании ssh сессии в хост-машине выделяется tty и связывается с pty в удаленной машине. Если дальше в удаленной машине попытаться создать еще одну ssh-сессию (соединение), то в рамках текущей ssh-сессии нельзя будет выделить tty, т.к. его там нет.
??: Смущает следующее: ssh localhost позволяет создать-таки ssh-сессию (пришлось подобрать пароль - `vagrant`) и тогда создается еще один pty и в рамках этой вложенной ssh-сессии команжа `tty` честно выдает его pts. И команда `w` тоже показывает два pty. Я подумаю об этом потом.\
Update: Вариант `ssh -t ...` тоже пробовал и видел, как вариант обхода сообщения `not a tty`.

Q13: Бывает, что есть необходимость переместить запущенный процесс из одной сессии в другую. Попробуйте сделать это, воспользовавшись reptyr. Например, так можно перенести в screen процесс, который вы запустили по ошибке в обычной SSH-сессии.\
A13: Что-то получилось после правки /etc/sysctl.d/10-ptrace.conf и ребута виртуальной машины. Но кейсы использования утилиты (пришлось его доставлять в виртуалку) неясны даже из матуала:()

Q14: sudo echo string > /root/new_file не даст выполнить перенаправление под обычным пользователем, так как перенаправлением занимается процесс shell'а, который запущен без sudo под вашим пользователем. Для решения данной проблемы можно использовать конструкцию echo string | sudo tee /root/new_file. Узнайте что делает команда tee и почему в отличие от sudo echo команда с sudo tee будет работать.\
A14: 
- sudo echo string > /... = сначала вызвает echo и редирект (т.е. под текущим пользователем, eще не под sudo) и ограничен в доступе к /root
- tee читает stdin и записывает в stdout или файл, соответственно sudo tee выполняется под sudo, поэтому этот процесс уже имеет доступ к /root


# Домашнее задание на тему "3.3. Операционные системы, лекция 1"

Q1: Какой системный вызов делает команда cd? В прошлом ДЗ мы выяснили, что cd не является самостоятельной программой, это shell builtin, поэтому запустить strace непосредственно на cd не получится. Тем не менее, вы можете запустить strace на /bin/bash -c 'cd /tmp'. В этом случае вы увидите полный список системных вызовов, которые делает сам bash при старте. Вам нужно найти тот единственный, который относится именно к cd. Обратите внимание, что strace выдаёт результат своей работы в поток stderr, а не в stdout.\
A1: Несмотря на формулировку вопроса, анализируя вывод предоагаемой команды, я увидел ДВА системных вызова:
- stat -> сначала была запрошена статистика по файлу, путь к которому передается команде cd в качестве аргумента;
- chdir -> собственно изменить рабочую директорию

Q2: Попробуйте использовать команду file на объекты разных типов на файловой системе. Например:
```bash
vagrant@netology1:~$ file /dev/tty
/dev/tty: character special (5/0)
vagrant@netology1:~$ file /dev/sda
/dev/sda: block special (8/0)
vagrant@netology1:~$ file /bin/bash
/bin/bash: ELF 64-bit LSB shared object, x86-64
```
Используя strace выясните, где находится база данных file на основании которой она делает свои догадки.\
A2: 
- Команда file делает системный вызов lstat, в ответ на который получает ответ, содержащий в том числе данные о типе файла в виде битовой маски в поле st_mode. Так же содержатся и данные о правах доступа (file mode and permission control).
- openat пытается найти файл для расшифровки по нескольким адресам: "/etc/magic.mgc", "/etc/magic", "/usr/share/misc/magic.mgc"). Но незная, что надо искать что-то магическое (magic), я бы в жизни не ответил на этот вопрос, т.к. openat чего только не открывает.

Q3: Предположим, приложение пишет лог в текстовый файл. Этот файл оказался удален (deleted в lsof), однако возможности сигналом сказать приложению переоткрыть файлы или просто перезапустить приложение – нет. Так как приложение продолжает писать в удаленный файл, место на диске постепенно заканчивается. Основываясь на знаниях о перенаправлении потоков предложите способ обнуления открытого удаленного файла (чтобы освободить место на файловой системе).\
A3.1: 
- определяем файловый дескриптор удаленного файла по его имени (`ls -la /proc/<pid>/fd`)
- перенаправляем файловый дескриптор в /dev/null\
- 
A3.2: (хотел бы получить обратную связь по еще одному варианту решения проблемы)
- определеяем <pid> попавшего в западню процесса
- определяем файловый дескриптор удаленного файла по его имени (`ls -la /proc/<pid>/fd`)
- вызываем strace -p <pid> -e trace=write. В выводе strace находим write, которые пытается сливать буффер в уже удаленный файл. Нужен write, который у которого в первом аргумент дескриптор удаленного файла.
- вызываем strace -p <pid> inject=write:error=EBADF - т.е. добавляем в вызов ошибку. Надо только как-то аккуратно выбрать нужный write через, например, when.
p.s. Я первый раз знакомлюсь со всей этой темой, поэтому пока просто фантазирую на основе прочитанных мануалов и статей. Всегда стараюсь найти больше 1 решения.

Q4: Занимают ли зомби-процессы какие-то ресурсы в ОС (CPU, RAM, IO)?\
A4: Нет, согласно определению зомби-процесса. Такой процесс занимает место только в таблице процессов, что может при большом числе процессов привести к блокировке сессии, т.к. больше места для новых процессов нет.

Q5: В iovisor BCC есть утилита opensnoop:
```bash
root@vagrant:~# dpkg -L bpfcc-tools | grep sbin/opensnoop
/usr/sbin/opensnoop-bpfcc
```
На какие файлы вы увидели вызовы группы open за первую секунду работы утилиты? Воспользуйтесь пакетом bpfcc-tools для Ubuntu 20.04. Дополнительные сведения по [установке](https://github.com/iovisor/bcc/blob/master/INSTALL.md).

A5: Предлагаемый BPF-скрипт показал, что системный вызов open() циклически обращается к следующему списку файлов
```bash
PID    COMM               FD ERR PATH
835    vminfo              6   0 /var/run/utmp
586    dbus-daemon        -1   2 /usr/local/share/dbus-1/system-services
586    dbus-daemon        18   0 /usr/share/dbus-1/system-services
586    dbus-daemon        -1   2 /lib/dbus-1/system-services
586    dbus-daemon        18   0 /var/lib/snapd/dbus-1/system-services/
1      systemd            12   0 /proc/560/cgroup
1      systemd            12   0 /proc/610/cgroup
835    vminfo              6   0 /var/run/utmp
586    dbus-daemon        -1   2 /usr/local/share/dbus-1/system-services
586    dbus-daemon        18   0 /usr/share/dbus-1/system-services
586    dbus-daemon        -1   2 /lib/dbus-1/system-services
586    dbus-daemon        18   0 /var/lib/snapd/dbus-1/system-services/
604    irqbalance          6   0 /proc/interrupts
604    irqbalance          6   0 /proc/stat
604    irqbalance          6   0 /proc/irq/20/smp_affinity
604    irqbalance          6   0 /proc/irq/0/smp_affinity
604    irqbalance          6   0 /proc/irq/1/smp_affinity
604    irqbalance          6   0 /proc/irq/8/smp_affinity
604    irqbalance          6   0 /proc/irq/12/smp_affinity
604    irqbalance          6   0 /proc/irq/14/smp_affinity
604    irqbalance          6   0 /proc/irq/15/smp_affinity
```
p.s. Надо потом погуглить, что за файловый дескриптор -1.

Q6: Какой системный вызов использует uname -a? Приведите цитату из man по этому системному вызову, где описывается альтернативное местоположение в /proc, где можно узнать версию ядра и релиз ОС.\
A6: 
- Используется одноименный системный вызов uname(2). 
- Цитата строки 50 из 63:
```bash
Part of the utsname information is also accessible via /proc/sys/kernel/{ostype, hostname, osrelease, version, domainname}. 
```

Q7: Чем отличается последовательность команд через ; и через && в bash? Например:
```bash
root@netology1:~# test -d /tmp/some_dir; echo Hi
Hi
root@netology1:~# test -d /tmp/some_dir && echo Hi
root@netology1:~#
```
Есть ли смысл использовать в bash &&, если применить set -e?\
A7: 
- Оба символа (; и &&) позволяют разделить последовательность команд, чтобы задать их выполнение одной строкой. Разница заключается в том, что
  - в случае \<comand1>; \<comand2> обе команда просто выполнятся одна за другой независимо от результата выполнения команды \<comand1>
  - в случае \<comand1> && \<comand2> команда \<comand2> выполнится только в случае успешного (штатного) завершения команды \<comand1>. Иными словами, && - это логическое ИЛИ между двумя командами. Успешность выполнения команды определяется ее exit-кодом.
- set позволяет изменить настройки bash, в частности ключ -e настраивает сессию так, что bash-скрипт (последовательность команд) прекращает свое выполнение в случае, если одна из команд завершилась с ненулевым exit-кодом. Цитата из set --help: Exit immediately if a command exits with a non-zero status. Таким образом, если применить set -e, то использование && никак не изменит ход выполнения скрипта (последовательности команд).

Q8: Из каких опций состоит режим bash set -euxo pipefail и почему его хорошо было бы использовать в сценариях.\
A8: Разберем набор ключей, настраивающих оболочку bash согласно содержанию вопроса:
- `-e` этот ключ мы уже разобрали в вопросе 7 - немедленно прекращать выполнение скрипта, если команда завершилась ненулевым кодом;
- `-u` = nounset. В мане, на удивление, нет развернутого описания, но гугл подсказывает, что в этом случае скрипт завершится, если будет попытка обратиться к необъявленной переменной;
- `-x` = xtrace. Опять в мане очень мало. Опять гугл: делать трассировку того, что выполняется в скрипте - полезно для дебага;
- `-o` позволяет задать настройку не через ключ, а через полное имя опции. В данному слачае, это опция `pipefail`;
- `pipefail` = the return value of a pipeline is the status of the last command to exit with a non-zero status, or zero if no command exited with a non-zero status. Переведу это как: При использовании pipeline, возвращаемое им значение соответствует статусу (exit-коду) последней команды с ненулевым exit-кодом. Если же все команды в pipeline выполнились успешно, то pipeline завершается нулевым exit-кодом. Так, видимо, можно быть уверенным, что все команды в pipeline выполнились успешно.\
Таким образом, предалагаемый набор настроек для bash очень удобен для дебага скрипта: выходим из скрипта в случае любой ошибки, трейсим все, что выполнилось.

Q9: Используя -o stat для ps, определите, какой наиболее часто встречающийся статус у процессов в системе. В man ps ознакомьтесь (/PROCESS STATE CODES) что значат дополнительные к основной заглавной буквы статуса процессов. Его можно не учитывать при расчете (считать S, Ss или Ssl равнозначными).\
A9: 
- В виртуальной машине Ubuntu (кстати, обратная связь авторам курса: лучше прямо скажите, что установка VirtualBox - хороший и простой вариант, дающий возможность выполнять ДЗ, а то мы в чатике переругались все на тему, зачем нам VirtualBox, если есть контейнеры. Пусть VirtualBox будет как PyCharm - инструментом)... так вот, в виртуальной машине у меня всего два процесса: собственно терминал со статусом S - interruptible sleep (waiting for an event to complete), и ps - со статусом R - running or runnable (on run queue).
- А вот в host-машине MacOs оказалось: что самый популярный статус процесса - это S, а еще там почему-то не было самого ps, если загрепать, то grep ps есть как процесс, а чистого ps нет:()
Update:
- после комментариев сделал так:
```bash
ps -eo stat | grep S | wc -l \\ получил 56
```
```bash
ps -eo stat | grep I | wc -l \\ получил 59
```
```bash
ps -eo stat | grep R | wc -l \\ получил 1
```

Итого, в виртуалке с небольшим отрывом лидируют I - Idle kernel thread. Проверка делалась на свежезагруженной ОС, поэтому среди процессов наиболее распространены процессы ядра в режиме ожидания.

P.s. интересная домашка, спасибо!

# Домашнее задание к занятию "3.4. Операционные системы, лекция 2"

Q1:На лекции мы познакомились с node_exporter. В демонстрации его исполняемый файл запускался в background. Этого достаточно для демо, но не для настоящей production-системы, где процессы должны находиться под внешним управлением. Используя знания из лекции по systemd, создайте самостоятельно простой unit-файл для node_exporter:
- поместите его в автозагрузку,
- предусмотрите возможность добавления опций к запускаемому процессу через внешний файл (посмотрите, например, на systemctl cat cron),
удостоверьтесь, что с помощью systemctl процесс корректно стартует, завершается, а после перезагрузки автоматически поднимается.\

A1: Создал файл с конфигом юнита службы, подложил его в /etc/systemd/system. Сделал systemctl enable <service name>. Перазагрузил daemon, загрепал systemctl list-units на предмет состояния моего кастомного сервиса. Перезагрузил вируальную машину. Node-exporter работает, curl http://localhost:9100/metrics выдает кучу метрик.

Q2: Ознакомьтесь с опциями node_exporter и выводом /metrics по-умолчанию. Приведите несколько опций, которые вы бы выбрали для базового мониторинга хоста по CPU, памяти, диску и сети.
A2: Могу предложить следующие опции:
- Для CPU: node_cpu_guest_seconds_total и node_cpu_seconds_total
- для памяти: node_memory_MemTotal_bytes
node_memory_MemFree_bytes
node_memory_MemAvailable_bytes
node_memory_Buffers_bytes
node_memory_Cached_bytes
- для диска: все, что начинается с node_disk, например, node_disk_io_time_seconds_total, node_disk_read_time_seconds_total и node_disk_write_time_seconds_total.
- для сети: все, что начинается с node_network, например, node_network_transmit_* or node_network_receive_*.

p.s. количество доступных метрик очень велико. С учетом отовдимого на ДЗ времени и необходимости самостоятельно разбираться в системах инициализации, создания юнитов, runlevel'ах, я представляю возможным разобраться в сути доступных метрик.

Q3: Установите в свою виртуальную машину Netdata. Воспользуйтесь готовыми пакетами для установки (sudo apt install -y netdata). После успешной установки:
- в конфигурационном файле /etc/netdata/netdata.conf в секции [web] замените значение с localhost на bind to = 0.0.0.0,
- добавьте в Vagrantfile проброс порта Netdata на свой локальный компьютер и сделайте vagrant reload:
config.vm.network "forwarded_port", guest: 19999, host: 19999

После успешной перезагрузки в браузере на своем ПК (не в виртуальной машине) вы должны суметь зайти на localhost:19999. Ознакомьтесь с метриками, которые по умолчанию собираются Netdata и с комментариями, которые даны к этим метрикам.\
A3: Сделал, как просили. Вот только секцию [web] пришлось добавть, а не редактировать. Выглядит красиво, серенький такой дизайн. Посмотрел (systemctl list-units | grep netdata), что сервис крутится. Поглядел его конфиг - солиднее, чем мой первый для node_exporter.

Q4: Можно ли по выводу dmesg понять, осознает ли ОС, что загружена не на настоящем оборудовании, а на системе виртуализации?\
A4: Я теряюсь, но вывод /var/log/dmesg вроде позволяет сказать, что ядро распознало среду, как вирутальную. По крайней мере systemd об этом сообщает:
```bash
systemd[1]: Detected virtualization oracle
```

Q5: Как настроен sysctl fs.nr_open на системе по-умолчанию? Узнайте, что означает этот параметр. Какой другой существующий лимит не позволит достичь такого числа (ulimit --help)?\
A5: 
- По умолчанию, лимит от количество открытых файловых дескрипторов равен 1048576.
- ulimit -n со своей стороны выдает всего 1024, и это ограничение сработает раньше.

Q6: Запустите любой долгоживущий процесс (не ls, который отработает мгновенно, а, например, sleep 1h) в отдельном неймспейсе процессов; покажите, что ваш процесс работает под PID 1 через nsenter. Для простоты работайте в данном задании под root (sudo -i). Под обычным пользователем требуются дополнительные опции (--map-root-user) и т.д.\
A6: Скриншот прилашается к ответу.

Q7: Найдите информацию о том, что такое :(){ :|:& };:. Запустите эту команду в своей виртуальной машине Vagrant с Ubuntu 20.04 (это важно, поведение в других ОС не проверялось). Некоторое время все будет "плохо", после чего (минуты) – ОС должна стабилизироваться. Вызов dmesg расскажет, какой механизм помог автоматической стабилизации. Как настроен этот механизм по-умолчанию, и как изменить число процессов, которое можно создать в сессии?\
A7: Создали функцию типа "forkbomb" и вызвали ее. Она создала кучу дочерних процессов пока не настал лимит по допустимому количеству процессов, по умолчанию имеем 3571. Изменить можно через ulimit -u 50. 

# Домашнее задание к занятию "3.5. Файловые системы"

Q1: Узнайте о sparse (разряженных) файлах.
A1: Если коротко, то sparse-файлы - это формат (структура) представления данных в бинарном виде, когда нулевые байты не записываются на диск, а отмечаются в структуре как запись о их местоположении. Т.к. нулевые байты в такой структуре не занимают место на диске, то такой подход позволяет эффективнее использовать дисковое пространство (со своими минусами).

Q2: Могут ли файлы, являющиеся жесткой ссылкой на один объект, иметь разные права доступа и владельца? Почему?\
A2: Нет, т.к. эти файлы предоставляют доступ к одной и той же информации (inode) в файловой системе, а, значит, к одной и той же структуре, в котором в том числе указаны права доступа.

Q3: Сделайте vagrant destroy на имеющийся инстанс Ubuntu. Замените содержимое...
A3: Уничтожили, создали новый конфиг, запустили новую VM, зашли в нее. Посмотрели, по какому адресу доступны два новых диска: `fdisk -l`. Диски доступны по адресам /dev/sdb и /dev/sdc.

Q4: Используя fdisk, разбейте первый диск на 2 раздела: 2 Гб, оставшееся пространство.
A4: 
- Разбил /dev/sdb на два раздела (оба primary) с указанными размерами, сохранил разметку в скрипт для sfdisk:
```bash
...
Enter script file name: sfdisk_task

Script successfully saved.

Command (m for help): w
The partition table has been altered.
Calling ioctl() to re-read partition table.
Syncing disks. 
```

Q5: Используя sfdisk, перенесите данную таблицу разделов на второй диск.\
A5:
- Сделал дамп конфигурации разбвивки /dev/sdb `sfdisk --dump /dev/sdb > sdb.dump`. Сравнил визуально sdb.dump и sfdisk_task. 
- Разбил /dev/sdc на разделы по той же схеме `afdisk /dev/sdc < sdb.dump`
```bash
Disklabel type: dos
Disk identifier: 0x596442f5

Device     Boot   Start     End Sectors  Size Id Type
/dev/sdc1          2048 3907583 3905536  1.9G 83 Linux
/dev/sdc2       3907584 5242879 1335296  652M 83 Linux

The partition table has been altered.
Calling ioctl() to re-read partition table.
Syncing disks. 
```
- еще можно было подгрузить разбивку из файла в утилите fdisk, указав ключ I.

Q6: Соберите mdadm RAID1 на паре разделов 2 Гб.\
A6: 
- по примеру из манула создал RAID1 больших разделов командой `mdadm --create /dev/md0 --level=1 --raid-devices=2 /dev/sd[bc]1`
```bash
mdadm: Note: this array has metadata at the start and
    may not be suitable as a boot device.  If you plan to
    store '/boot' on this device please ensure that
    your boot-loader understands md/v1.x metadata, or use
    --metadata=0.90
Continue creating array? y
mdadm: Defaulting to version 1.2 metadata
mdadm: array /dev/md0 started.
```
- посмотрел на результат через `fdisk -l`
```bash
Disk /dev/md0: 1.88 GiB, 1997537280 bytes, 3901440 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
```

Q7: Соберите mdadm RAID0 на второй паре маленьких разделов.
A7:
- повторил с маленькими разделами `mdadm --create /dev/md1 --level=0 --raid-devices=2 /dev/sd[bc]2`
```bash
...
mdadm: array /dev/md1 started.
```
- fdisk -l показал 2 массива
```bash
Disk /dev/md0: 1.88 GiB, 1997537280 bytes, 3901440 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes


Disk /dev/md1: 1.28 GiB, 1363148800 bytes, 2662400 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 524288 bytes / 1048576 bytes
```

Q8: Создайте 2 независимых PV на получившихся md-устройствах.\
A8: 
- командой `pvcreate /dev/md0` создал физический том в системе LVM2
```bash
  Physical volume "/dev/md0" successfully created.
```
- повторил для /dev/md1
```bash
  Physical volume "/dev/md1" successfully created.
```

Q9: Создайте общую volume-group на этих двух PV.
A9: командой `vgcreate vg_on_raid /dev/md0 /dev/md1` создал из физических томов группу с именем vg_on_raid, посмотрел на нее через vgdisplay
```bash
--- Volume group ---
  VG Name               vg_on_raid
  System ID
  Format                lvm2
  Metadata Areas        2
  Metadata Sequence No  1
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                0
  Open LV               0
  Max PV                0
  Cur PV                2
  Act PV                2
  VG Size               3.12 GiB
  PE Size               4.00 MiB
  Total PE              800
  Alloc PE / Size       0 / 0
  Free  PE / Size       800 / 3.12 GiB
  VG UUID               yRYlmG-QZdm-sV4L-MY4I-a54P-zMM1-J2OAL1
```

Q10: Создайте LV размером 100 Мб, указав его расположение на PV с RAID0.\
A10: командой `lvcreate -n small_lv -L 100m vg_on_raid /dev/md1` создал логический том размером 100Мб на pv /dev/md1
```bash
root@vagrant:~# lvs
  LV       VG         Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  small_lv vg_on_raid -wi-a----- 100.00m
  root     vgvagrant  -wi-ao---- <62.54g
  swap_1   vgvagrant  -wi-ao---- 980.00m
```

Q11: Создайте mkfs.ext4 ФС на получившемся LV.\
A11: командой `mkfs.ext4 /dev/vg_on_raid/small_lv` создал файловую систему на логическом диске
```bash
mke2fs 1.45.5 (07-Jan-2020)
Creating filesystem with 25600 4k blocks and 25600 inodes

Allocating group tables: done
Writing inode tables: done
Creating journal (1024 blocks): done
Writing superblocks and filesystem accounting information: done
```

Q12: Смонтируйте этот раздел в любую директорию, например, /tmp/new.\
A12: создал директорию /tmp/new и командой `mount /dev/vg_on_raid/small_lv /tmp/new` смонтировал логический диск в директорию. Команда закончилась бесшумно, логи отсутствуют.

Q13: Поместите туда тестовый файл, например wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz\
A13: директории появился первый файл
```bash
total 22M
drwx------ 2 root root 16K Nov 29 14:01 lost+found
-rw-r--r-- 1 root root 22M Nov 29 09:55 test.gz
```

Q14: Прикрепите вывод lsblk.\
A14: Итого имею такую структуру блоковых устройств
```bash
root@vagrant:/tmp/new# lsblk
NAME                      MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
sda                         8:0    0   64G  0 disk
├─sda1                      8:1    0  512M  0 part  /boot/efi
├─sda2                      8:2    0    1K  0 part
└─sda5                      8:5    0 63.5G  0 part
  ├─vgvagrant-root        253:0    0 62.6G  0 lvm   /
  └─vgvagrant-swap_1      253:1    0  980M  0 lvm   [SWAP]
sdb                         8:16   0  2.5G  0 disk
├─sdb1                      8:17   0  1.9G  0 part
│ └─md0                     9:0    0  1.9G  0 raid1
└─sdb2                      8:18   0  652M  0 part
  └─md1                     9:1    0  1.3G  0 raid0
    └─vg_on_raid-small_lv 253:2    0  100M  0 lvm   /tmp/new
sdc                         8:32   0  2.5G  0 disk
├─sdc1                      8:33   0  1.9G  0 part
│ └─md0                     9:0    0  1.9G  0 raid1
└─sdc2                      8:34   0  652M  0 part
  └─md1                     9:1    0  1.3G  0 raid0
    └─vg_on_raid-small_lv 253:2    0  100M  0 lvm   /tmp/new
```
вижу, что `/tmp/new` "опирается" на два раздела: /dev/sdb2 и /dev/sdc2

Q15: Протестируйте целостность файла..\
A15: протестировал и получил
```bash
root@vagrant:/tmp/new# gzip -t /tmp/new/test.gz
root@vagrant:/tmp/new# echo $?
0
```

Q16: Используя pvmove, переместите содержимое PV с RAID0 на RAID1.\
A16: командой `pvmove /dev/md1 /dev/md0` перемещаем физические тома
```bash
root@vagrant:/# pvmove /dev/md1 /dev/md0
  /dev/md1: Moved: 60.00%
  /dev/md1: Moved: 100.00%
```

Q17: Сделайте --fail на устройство в вашем RAID1 md.\
A17: командой `mdadm /dev/md0 -f /dev/sdb1` пометили устройство /dev/sdb1 как "сломанное".

Q18: Подтвердите выводом dmesg, что RAID1 работает в деградированном состоянии.\
A18: На действия из вопроса 17 ядро отреагировало сообщением (dmesg):
```bash
[ 7849.260952] md/raid1:md0: Disk failure on sdb1, disabling device.
               md/raid1:md0: Operation continuing on 1 devices.
```

Q19: Протестируйте целостность файла, несмотря на "сбойный" диск он должен продолжать быть доступен...
A19: тест на целостность прошел успешно
```bash
root@vagrant:/# gzip -t /tmp/new/test.gz
root@vagrant:/# echo $?
0
```
хорошо, что сделалми pvmove

Q20: Погасите тестовый хост, vagrant destroy.\
A20: Выкулючаем вирутальную машину, делаем коммит и отправляем ДЗ на проверку. Спасибо за ДЗ и обратную связь по нему.